% !TeX source = ../main.tex

\chapter{Saddle point problems}\label{chap:saddle}

\section{BNB conditions}\label{sec:bnb}
In this section we will examine a more general version of the classic problem \eqref{eqn:weak_laxmilgram}, in which the target space of the operator $A$ is allowed to be different from the dual space of the domain.
\begin{remark}
    Recall that a Banach space $W$ is said to be \emph{reflexive} if the natural map from $W$ to $W''$ is an isomorphism (it is, in fact, a canonical isomorphism, since it does not depend on the choice of a basis). This map takes a vector $w$ and associates it to the linear map $J_w$ such that $J_w(f)=f(w)$ for every $f\in W'$. In practice we require this hypothesis so that we can identify $W=W''$.
\end{remark}
Consider a Banach space $V$ and a \emph{reflexive} Banach space $W$. As usual, we have the option to either consider a linear continuous operator $A\in\L(V;W')$ or a bilinear operator $a\in\L(V\times W;\R)$. Given $f\in W'$, the problem we want to solve is: find $u\in V$ such that
\begin{equation}\label{eqn:weak_bnb}
    Au=f \ \text{in} \ W', \ \text{or equivalently} \ a(u,w) = \langle f,w \rangle \ \forall w\in W,
\end{equation}
where as usual $a(\cdot,\cdot)$ is defined by $a(u,w):=\langle Au,w \rangle$ for all $u\in V$ and $w\in W$.\par
The first question we must ask ourselves is whether the problem is well-posed. Note that we can not rely on the Lax-Milgram Lemma since here the bilinear operator is $a:V\times W\to \R$, with $V\neq W$ in general.
\begin{definition}\label{eqn:BNB}\marginpar{BNB conditions}
    A problem of the form \eqref{eqn:weak_bnb} is said to be \emph{well-posed} (in the sense of Hadamard) if the following two conditions are satisfied:
    \begin{itemize}
        \item for every $f\in W'$, there exists a unique $u\in V$ such that $Au=f$,
        \item $A$ is bounding, i.e. there exists $\alpha>0$ such that $\norm{u}_V \leq \tfrac{1}{\alpha}\norm{Au}_{W'}$ for every $u\in V$.
    \end{itemize}
\end{definition}
The previous two conditions are also known as \emph{BNB (Banach-Ne\v{c}as-Babu\v{s}ka) conditions} in the literature.
\begin{remark}\label{rmk:bnb_conditions}
	The BNB conditions can be summarized by saying that $A$ is required to be:
	\begin{enumerate}
		\item injective,
		\item surjective,
		\item bounding.
	\end{enumerate}
	Note that injectivity is implied by being bounding, since no element in $\ker A$, other than zero, can satisfy the bounding condition.
\end{remark}


\subsection{Open mapping and closed range theorems}
\rev{This subsection is a bit reworked from the lecture notes. Main reference: Brezis, \emph{Functional Analysis}.}

Injectivity, surjectivity and the bounding condition are all different aspects of the \emph{open mapping theorem} and the \emph{closed range theorem}. Let us recall them in a general setting.

\begin{theorem}[Open mapping theorem]\label{thm:open_mapping}
	Let $A: X \to Y$ be a surjective linear continuous map between Banach spaces. Then $A$ is an open mapping, i.e., if $U \subset X$ is an open set, then also $A(U)$ is open.
\end{theorem}

It is also worth recalling the closed graph theorem.
\begin{theorem}[Closed graph theorem]\label{thm:closed_graph}
	Let $A: X \to Y$ be a linear operator between Banach spaces. Then, the following are equivalent:
	\begin{itemize}
		\item $A$ is continuous,
		\item the graph of $A$ is closed in $X \times Y$.
	\end{itemize}
\end{theorem}
Remember that the graph of a map $A: X \to Y$ is the set
\[
G(A) := \{(x,Ax) : x \in X\}.
\]

Before we look at the closed range theorem, some preliminary definitions are needed.
\begin{definition}
	Let $X$ be a Banach space. If $Z \subset X$ is a linear subspace, we define the \emph{annihilator} of $Z$ as the set
	\[
	Z^\perp = \{f \in X' : \langle f, z \rangle = 0 \, \forall z \in Z\}.
	\]
	If $W \subset X'$ is a linear subspace of the dual $X'$, its annihilator is the set
	\[
	W^\perp = \{x \in X : \langle f, x \rangle = 0 \, \forall f \in W\}.
	\]
\end{definition}
\rev{A bit of a philological matter. After doing some research (Wikipedia, some textbooks and articles), there seems to be no clear consensus on the meaning of "polar" and the $^o$ symbol: it seems to be used as a synonym of "annihilator" in the context of PDE discretization, in particular by Brezzi, while in other contexts has different meanings. On the other hand, "annihilator" seems to be more widely used in functional analysis. This is why, for the moment, I preferred "annihilator" with the $^\perp$ symbol.}

In the PDE discretization literature, annihilators are also called \emph{polar} sets and the $^o$ symbol is used. It is easy to see that the annihilator of a subspace is closed. Moreover, it can be showed that:
\begin{itemize}
	\item if $Z \subset X$, then $(Z^\perp)^\perp = \overline{Z}$,
	\item if $W \subset X'$, then $(W^\perp)^\perp \supset \overline{W}$.
\end{itemize}
Unfortunately, the use of $\supset$ when $W \subset X'$ cannot be avoided, as there are examples in which $(W^\perp)^\perp$ is strictly bigger than $\overline{W}$. However, equality holds when $X$ is reflexive. For an extensive reference, see \textbf{[insert Brezis ref, eventually]}.

\begin{definition}
	Let $X$, $Y$ be Banach spaces. Given $A \in \L(X;Y)$, its \emph{transpose} is the operator $A^T \in \L(Y';X')$ given by
	\[
	\langle A^T y', x \rangle_{X',X} = \langle y', Ax \rangle_{Y',Y} \qquad x \in X, y' \in Y'.
	\]
\end{definition}
In the definition, it has been remarked explicitly that the duality pairings which appear at each side of the equal are different.

The closed range theorem works with slightly more general operators than the ones that we have considered so far.
\begin{definition}
	Let $X$, $Y$ be Banach spaces. An \emph{unbounded linear operator} is a linear map $A: D(A) \subset X \to Y$ such that the domain $D(A)$ is a linear subspace of $X$.
	
	We say that $A$ is \emph{densely defined} if $D(A)$ is dense in $X$.
\end{definition}
Linear continuous operators can be seen as unbounded operators which are bounded and satisfy $D(A) = X$.
The definition of transpose can be extended to work with unbounded linear operators as well.

An operator $A$ is linked to its transpose by the following relations:
\begin{align}\label{eqn:ker-im-relations}
	\ker A &= \im (A^T)^\perp \\
	\ker (A^T) &= \im A^\perp.
\end{align}
These can be easily proven by writing down the definitions. If we recall that, by continuity, the kernel of a linear continuous map is closed, these equalities are also consistent from a topological point of view. A different picture comes out when trying to swap the kernel with the image. In general, we get
\begin{align}
	\ker A^\perp &\supset \overline{\im (A^T)} \\
	\ker (A^T)^\perp &= \overline{\im A},
\end{align}
which follows after taking the annihilator at each side of the equal and recalling the observations above on the behavior of $(Z^\perp)^\perp$. Nevertheless, with further hypotheses we can still obtain equalities.

\begin{theorem}[Closed range theorem]\label{thm:closed_range}
	Let $A: D(A) \subset X \to Y$ be an unbounded linear operator which is densely defined and closed (i.e., its graph G(A) is closed). Then, the following properties are equivalent:
	\begin{enumerate}
		\item $\im A$ is closed,
		\item $\im (A^T)$ is closed,
		\item $\im A = \ker (A^T)^\perp$,
		\item $\im (A^T) = \ker A^\perp$.
	\end{enumerate}
\end{theorem}

Returning to the setting of Problem \eqref{eqn:weak_bnb}, we discover that the operator $A \in \L(V;W')$ and its transpose $A^T$ automatically satisfy the assumptions of the closed range theorem, thanks to the closed graph theorem \ref{thm:closed_graph}.
In particular, from \eqref{eqn:ker-im-relations} we deduce that the following implications hold in general:
\begin{align}
	\text{$A$ surjective} &\implies \text{$A^T$ injective} \\
	\text{$A^T$ surjective} &\implies \text{$A$ injective}
\end{align}
The converses fail, unless we can prove that either $\im A$ or $\im (A^T)$ is closed. This is true, in particular, when we deal with finite dimensional spaces: in that case, any subspace is closed by default.

\begin{example}
	To better understand what might go wrong in infinite dimensions, consider the inclusion
	\[
	A: H_0^1(\Omega) \hookrightarrow L^2(\Omega) = \bigl(L^2(\Omega)\bigr)',
	\]
	i.e., $Au = u$ for all $u\in H_0^1(\Omega)$. Clearly, $\ker(A)=\{0\}$, but $A$ is not surjective: in fact, functions with a jump discontinuity can be in $L^2$ but not in $H^1_0$. Moreover, $\im A = H_0^1(\Omega)$ is dense in $L^2(\Omega)$ because $H_0^1$ is the closure of $C_0^\infty$, which is dense in $L^2$. Hence, $\im A\neq\overline{\im A}$.
	
	If we were in finite dimensions, $\ker A = \{0\}$ would be sufficient for $A$ to be invertible. However, let us look at this example from another point of view. The transpose operator $A^T: L^2(\Omega) \to \bigl(H_0^1(\Omega)\bigr)'$ satisfies
	\[
	(A^T q)(u) = \int_{\Omega} uq \qquad \forall q \in L^2(\Omega).
	\]
	If $(A^T q)(u) = 0$ for every $u \in H_0^1(\Omega)$, then $q = 0$, thanks to standard results (fundamental lemma of calculus of variations). Hence, $\ker (A^T)$ is trivial. In finite dimensions, having $\ker (A^T) = \{0\}$ would imply that $A$ is surjective, which is not the case.
\end{example}


\subsection{Conditions equivalent to BNB}

\begin{theorem}\label{thm:closed_range2}
    Let $A\in\L(V;W')$ for $V,W$ Banach spaces. Then the following are equivalent:
    \begin{enumerate}
        \item $\im A = \overline{\im A}$,
        \item there exists $\alpha >0$ such that
        \begin{equation}
        	\forall w' \in \im A \, \exists u \in V \, \text{s.t. }\, Au = w' \, \text{and }\, \norm{Au}_{W'} = \norm{w'}_{W'} \ge \alpha\norm{u}_V.
        \end{equation}
    \end{enumerate}
\end{theorem}
\begin{proof}
    \hfill
    \begin{enumerate}[itemindent=25pt]
        \item[1. $\implies$ 2.] By hypothesis, $\im A$ is a closed linear subspace of $W'$, hence it is a Banach space. As a consequence, $A: V \to \im A$ is still a linear continuous operator, moreover it is surjective. Consider now the open unit ball $B_1(0_V)$: by the open mapping theorem, $A(B_1(0_V))\subseteq\im A$ is open in $\im A$. Therefore, being $A(0_V)=0_{W'}$ by linearity, there exists $\gamma>0$ such that $B_\gamma(0_{W'})\subseteq A(B_1(0_V))$.\par
        Pick any $\alpha < \gamma$ and let $w'\in \im A$. If $w' = 0_{W'}$, then it is sufficient to choose $u = 0_V$. Otherwise, $\overline{w'}:=\alpha\frac{w'}{\norm{w'}_{W'}}\in B_\gamma(0_{W'})$, which is contained in the image of $B_1(0_V)$. This in turn implies the existence of a vector $z\in B_1(0_V)$ such that $Az=\overline{w'}$.\par
        From this, we can easily conclude: take $u:=\frac{\norm{w'}_{W'}}{\alpha}z$, so that $Au=w'$. Then we have
        \begin{equation*}
            \norm{u}_V=\frac{\norm{w'}_{W'}}{\alpha}\norm{z}_V\leq\frac{\norm{w'}_{W'}}{\alpha}=\frac{\norm{Au}_{W'}}{\alpha}.
        \end{equation*}
        \item[2. $\implies$ 1.] We need to prove that $\im A$ is closed in $W'$. Take a Cauchy sequence $\{w_n'\}\subset \im A$ and let $w'\in W'$ be its limit. If we prove that $w'\in\im A$ we are done. For every $w_n'$, take $v_n\in V$ such that $Av_n=w_n'$. Then
        \begin{equation*}
            \norm{w_n'-w_m'}_{W'}=\norm{A(v_n-v_m)}_{W'}\geq\alpha\norm{v_n-v_m}_V,
        \end{equation*}
        hence also $\{v_n\}$ is Cauchy in $V$. If we call $v\in V$ the limit, by continuity of $A$ we must have $Av=w'$.
    \end{enumerate}
\end{proof}

It is useful to relate the bounding condition to other equivalent properties.
\begin{proposition}\marginpar{inf-sup condition}\label{prop:inf-sup_condition}
    Let $V, W$ be Banach spaces, with $W$ reflexive. Let $A\in\L(V;W')$. Then the following are equivalent:
    \begin{enumerate}
    	\item $A^T \in \L(W,V')$ is surjective.
    	\item $A$ is injective and $\im A = \overline{\im A}$.
    	\item $A$ is bounding.
    	\item The \emph{inf-sup condition} is satisfied:
		\begin{equation}\label{eqn:infsup_condition}
			\exists \, \alpha>0 \, \text{s.t. } \inf_{u\in V}\sup_{w\in W}\frac{\langle Au,w \rangle}{\norm{u}_V\norm{w}_W} \ge \alpha.
		\end{equation}    	
    \end{enumerate}
\end{proposition}
\begin{proof}
	The equivalence between 3. and 4. follows directly from the definition of operator norm:
	\[
	\norm{Au}_{W'} = \sup_{w\in W}\frac{\langle Au,w \rangle}{\norm{w}_W}.
	\]
	In fact, the inf-sup condition can be rewritten as
	\begin{equation*}
		\inf_{u\in V}\frac{\norm{Au}_{W'}}{\norm{u}_V}\geq\alpha,
	\end{equation*}
	which is clearly equivalent to the bounding condition.
		
	Let us prove that 1. $\iff$ 2. $\iff$ 3.
	\begin{enumerate}[itemindent=25pt]
		\item[1. $\implies$ 3.] Assume that this is not the case; then there exists a sequence $\{v_n\}\subset V$ with $\norm{v_n}_{V}=1$ and $\norm{Av_n}_{W'}<1/n$ for all $n\in\N$. Note that, since $\norm{v_n}_{V}=1$, for every $n$ there exists a functional $v_n'\in V'$ such that $|v_n'(v_n)|\geq 1/2$. Since $A^T$ is surjective, by the open mapping theorem there exists $\gamma > 0$ such that $A^T(B_1(0_W))$ contains $B_\gamma(0_{V'})$. Thus we get a sequence $\{w_n\}\subset B_1(0_W)$ such that $A^Tw_n=\gamma v_n'$ for all $n$. Finally, observe that this implies that
		\begin{equation*}
			|Av_n(w_n)|=|A^Tw_n(v_n)|=\gamma|v_n'(v_n)|\geq\gamma/2,
		\end{equation*}
		hence $\norm{Av_n}_{W'}\geq\gamma/2$, a contradiction.
		\item[3. $\implies$ 2.] This is a consequence of Theorem \ref{thm:closed_range2}, together with Remark \ref{rmk:bnb_conditions}.
		\item[2. $\implies$ 1.] Being $\im A$ closed, the closed range theorem \ref{thm:closed_range} implies that $\im (A^T) = (\ker A)^\perp$. Since $A$ is injective, $(\ker A)^\perp = V$.
	\end{enumerate}
\end{proof}

In a similar fashion, if $V$ is reflexive as well, one can prove an analogous result for $A^T\in\L(W;V')$. Putting things together, we get an interesting consequence.
\begin{theorem}\label{thm:bnb_boundingness}
	Let $V$, $W$ be reflexive Banach spaces, let $A \in \L(V;W')$. Then, $A$ satisfies the BNB conditions \eqref{eqn:BNB} if and only if both $A$ and $A^T$ are bounding, i.e., there exists $\alpha>0$ such that
	\begin{enumerate}
		\item $\norm{Au}_{W'}\geq\alpha\norm{u}_V \quad  \forall u \in V$,
		\item $\norm{A^Tw}_{V'}\geq\alpha\norm{w}_W \quad  \forall w \in W$.
	\end{enumerate}
\end{theorem}

\begin{remark}
	The bounding conditions above can be more suggestively written as
	\begin{align}
		\inf_{u\in V}\sup_{w\in W}\frac{\langle Au,w \rangle}{\norm{u}_V\norm{w}_W}&\geq\alpha \\
		\inf_{w\in W}\sup_{u\in V}\frac{\langle Au,w \rangle}{\norm{u}_V\norm{w}_W}&\geq\alpha.
	\end{align}
	This is true whenever both $V$ and $W$ are reflexive. In particular, when they are Hilbert spaces.
	\rev{In the teacher's notes it is said that this is true in a Hilbert setting, but there seems to be no problem also if both the spaces are Banach+reflexive. Am I wrong?}
\end{remark}

\begin{corollary}
	Using the notations above, assume that $V=W$ are Hilbert spaces and that $A$ is $\alpha$-elliptic. Then ``Lax-Milgram implies BNB'', i.e., if the hypotheses of Lemma \ref{lemma:lax-milgram} are satisfied, then BNB conditions \eqref{eqn:BNB} hold.
\end{corollary}
\begin{proof}
	It suffices to note that, thanks to ellipticity,
	\[
	\sup_{w\in W}\frac{\langle Au,w \rangle}{\norm{w}} \geq 
	\frac{\langle Au,u \rangle}{\norm{u}} \geq\alpha,
	\]
	then apply Theorem \ref{thm:bnb_boundingness} in its inf-sup version.
\end{proof}

\rev{There's a remark in my notes on why the converse is not true. Insert something.}

\rev{I added the following technical lemma because it is implicitly used in the mixed problems section.}

Before we move to the next section, let us make one final remark that will be useful in the context of mixed problems. Suppose that $V$ and $W$ are both reflexive Banach spaces and let $A \in \L(V;W')$ be a surjective operator. Thanks to Proposition \ref{prop:inf-sup_condition}, we know that $A^T$ is bounding:
\[
\norm{A^T w}_{V'} \ge \alpha \norm{w}_W \quad \forall w \in W.
\]
Furthermore, surjectivity ensures that $\im A$ is closed, hence by Theorem \ref{thm:closed_range2} there exists another constant $\overline{\alpha}>0$ such that
\begin{equation}
	\forall w' \in \im A \, \exists u \in V \, \text{s.t. }\, Au = w' \, \text{and }\, \norm{w'}_{W'} \ge \overline{\alpha}\norm{u}_V.
\end{equation}
Are these constants in fact the same? The answer is yes. A precise statement is provided below, without proof: it is a slight adaptation of Lemma A.42 in \cite{eg04}.
\begin{lemma}\label{lemma:const-uniqueness}
	Let $V$ and $W$ be two Banach spaces, with $W$ reflexive, and let $A \in \L(V;W')$ be a surjective operator. Let $\alpha>0$. The property
	\begin{equation}
		\forall w' \in \im A \, \exists u \in V \, \text{s.t. }\, Au = w' \, \text{and }\, \norm{w'}_{W'} \ge \alpha\norm{u}_V
	\end{equation}
	implies
	\begin{equation}
		\inf_{w\in W}\sup_{u\in V}\frac{\langle Au,w \rangle}{\norm{u}_V\norm{w}_W}\geq\alpha.
	\end{equation}
	The converse is true if $V$ is reflexive.	
\end{lemma}


\section{Petrov-Galerkin method}

\subsection{A priori bound for the error}

Let us consider the discrete counterpart of Problem \eqref{eqn:weak_bnb}, in its most general form: given $f\in W'$, find $u_h\in V_h$ such that
\begin{equation}\label{eqn:petrov-galerkin}\marginpar{Petrov-Galerkin method}
	\langle A_h u_h, w_h \rangle= \langle f_h, w_h \rangle \quad \forall w_h\in W_h.
\end{equation}
In particular, $A_h \in \L(V_h, {W_h}')$ and $f_h \in {W_h}'$ are the discrete-level approximations of the operator $A$ and the functional $f$, respectively. When the spaces $V_h$ and $W_h$ are different, this approximation method is also called \emph{Petrov-Galerkin method}.

Similarly to previous chapters, we say that the approximation setting is \emph{conformal} if $V_h \subset V$ and $W_h \subset W$, \emph{non-conformal} otherwise. In particular, as seen in Section \ref{sec:strang}, having $A_h \ne A$, $f_h \ne f$ and/or working in a non-conformal setting requires the use of Strang's lemmas. Therefore, it is important that the spaces $\tilde{V} = V + V_h$ and $\tilde{W} = W + W_h$ can be equipped with norms $\tnorm{\cdot}_{\tilde{V}}$ and $\tnorm{\cdot}_{\tilde{W}}$ such that:
\begin{enumerate}
	\item $\tnorm{v_h}_{\tilde{V}} = \norm{v_h}_{V_h}$ for all $v_h \in V_h$,
	\item $\tnorm{v}_{\tilde{V}} \le c \norm{v}_V$ for all $v \in V$, i.e., the embedding $V \hookrightarrow \tilde{V}$ is continuous.
\end{enumerate}
%Of course, the same properties must hold for the other norm $\tnorm{\cdot}_{\tilde{W}}$ as well.
\rev{Looking at Guermond's book, it seems that the assumption on the three-bar norm is needed only in the solution space. Is it true? Also todo: fix possible inconsistencies with the Strang's lemmas section.}

\begin{example}
	The three-bar norm which was introduced in Section \ref{sec:sipg} for the SIPG method satisfies the embedding property, in particular equality holds with $c = 1$.
\end{example}

As we have done for the original problem in Section \ref{sec:bnb}, we have to make sure that the approximate counterpart is well-posed as well. Therefore, a different set of BNB conditions, which will be denoted as "BNB$_h$" or \emph{discrete BNB conditions}, must be satisfied. Once BNB and BNB$_h$ conditions are proved, we are guaranteed the existence and uniqueness of solutions to the original and approximate problem, say $u$ and $u_h$. The next step is producing an \emph{a priori} bound for the error $\tnorm{u - u_h}_{\tilde{V}}$.

\begin{definition}[Approximability]
	The approximation setting is said to have the \emph{approximability} property if
	\begin{equation}
		\lim_{h \to 0} \left( \inf_{v_h \in V_h} \tnorm{v - v_h}_{\tilde{V}} \right) = 0 \quad \forall v \in V.
	\end{equation}
\end{definition}

\begin{definition}[Consistency]
	Let $u \in V$ solve Problem \eqref{eqn:weak_bnb}.
	The approximation setting is said to be \emph{consistent} if $A_h$ can be extended to a functional in $\L(\tilde{V}, {W_h}')$ and if $u$ is also a solution to the discrete problem \eqref{eqn:petrov-galerkin}, i.e.,
	\[
		\langle A_h u, w_h \rangle= \langle f_h,w_h \rangle \ \quad \forall w_h\in W_h.
	\]
\end{definition}

\begin{remark}
	If the approximation setting is consistent, then the immediate consequence is a \emph{Galerkin orthogonality} property:
	\[
	\langle A_h (u-u_h) , v_h \rangle = 0 \quad \forall v_h \in W_h.
	\]
	Moreover, BNB conditions automatically imply the BNB$_h$ ones, because...
	\rev{add proof}
	However, when employing quadrature formulas or using non-conformal methods, consistency cannot be expected.
\end{remark}

\begin{definition}[Asymptotic consistency]
	Let $u \in V$ solve Problem \eqref{eqn:weak_bnb}.
	The approximation setting is said to be \emph{asymptotically consistent} if there is an operator $\Pi_h: V \to V_h$ such that:
	\begin{enumerate}
		\item there exists $c>0$ such that
		\begin{equation}
			\tnorm{\Pi_h v - v}_{\tilde{V}} \le c \inf_{v_h \in V_h} \tnorm{v - v_h}_{\tilde{V}} \quad \forall v \in V.
		\end{equation}
		\item $\lim_{h \to 0} R_h(u) = 0$, where $R_h(u)$ is the \emph{consistency error}
		\[
		R_h(u) := \norm{A_h \Pi_h u - f_h}_{{W_h}'} = \sup_{w_h \in W_h} \frac{\vert \langle A_h \Pi_h u - f_h, w_h \rangle \vert}{\norm{w_h}_{W_h}}.
		\]
	\end{enumerate}
\end{definition}

\rev{Checklist, referring to Guermond's book:
	\begin{itemize}
		\item The book requires $A_h$ to be "uniformly bounded" on its domain, but I think this is already ok if we assume that $A_h$ is linear continuous.
		\item There is a remark on the independence of asymptotic consistency from the operator $\Pi_h$ if we have approximability. Insert it?
	\end{itemize}}

When setting the discrete problem, the goal is to ensure approximability and asymptotic consistency. In fact, taking advantage of the BNB$_h$ conditions, we would get:
\begin{align}
	\tnorm{u - u_h}_{\tilde{V}} &\le \tnorm{u - \Pi_h u}_{\tilde{V}} + \tnorm{\Pi_h u - u_h}_{\tilde{V}} \\
	&= \tnorm{u - \Pi_h u}_{\tilde{V}} + \norm{\Pi_h u - u_h}_{V_h} \\
	&\le c \inf_{v_h \in V_h} \tnorm{u - v_h}_{\tilde{V}} + \frac{1}{\alpha_h} \norm{A_h (\Pi_h u - u_h)}_{{W_h}'} \\
	&= c \inf_{v_h \in V_h} \tnorm{u - v_h}_{\tilde{V}} + \frac{1}{\alpha_h} R_h(u),
\end{align}
where $\alpha_h$ is the constant in the discrete inf-sup condition. Hence the error would tend to zero as $h \to 0$, provided that $\alpha_h \ge \alpha_0 > 0$ for every $h$. Indeed, $\alpha_h$ is generally different from the $\alpha$ in the continuous inf-sup, and establishing a lower bound for it is often the main difficulty. 


\subsection{The Hilbert case in a simpler setting}

Let us analyze a more specific situation. Let $V$, $Q$ be Hilbert spaces and consider, for simplicity, a conformal approximation, i.e., $V_h\subset V$ and $Q_h\subset Q$. Let $A\in\L(V;Q')$ be a linear continuous operator and let $A_h\in\L(V_h;Q_h')$ be its discretization.

The continuous problem is: given $f \in Q'$, find $u \in V$ such that $Au = f$ in $Q'$, i.e.
\begin{equation}\label{eqn:bnb-hilb}
	\langle Au, q \rangle = \langle f, q \rangle \quad \forall q \in Q.
\end{equation}

When dealing with conformal spaces, one typically assumes that $A_h$ acts on test functions just as $A$, but only in the space $Q_h$. Therefore, the discrete version of Problem \eqref{eqn:bnb-hilb} is: given $f\in Q'$, find $u_h\in V_h$ such that
\begin{equation}\label{eqn:petrov-galerkin-hilb}
    \langle Au_h, q_h \rangle= \langle f,q_h \rangle \quad \forall q_h\in Q_h.
\end{equation}
To get a concrete expression for $A_h$ and $f_h$, however, it is useful to assume the existence of two \emph{projection} operators from the whole space to the discrete space $\Pi_h:V\to V_h$ and $P_h:Q\to Q_h$. In fact, being $\Pi_h u_h = u_h$ and $P_h q_h = q_h$, Problem \eqref{eqn:petrov-galerkin-hilb} can be rewritten as
\[
	\langle A \Pi_h u_h, P_h q_h \rangle= \langle f, P_h q_h \rangle \iff
	\langle P_h^T A \Pi_h u_h, q_h \rangle= \langle P_h^T f, q_h \rangle
\]
hence $A_h = P_h^T A \Pi_h$ and $f_h = P_h^T f$. The formulation with $A_h$ and $f_h$ is perfectly equivalent to the one in \eqref{eqn:petrov-galerkin-hilb}.

\begin{remark}
    If $u$ is a solution to the continuous problem, then $\langle Au,q_h\rangle=\langle f,q_h\rangle$ for all $q_h\in Q_h\subset Q$. At the same time, given a solution $u_h$ to the discrete problem, we have $\langle Au_h,q_h\rangle=\langle f,q_h\rangle$ for all $q_h\in Q_h$. Subtracting the two gives us
    \begin{equation}\label{eqn:petrov-galerkin orthogonality}
        \langle A(u-u_h),q_h \rangle=0 \quad \forall q_h\in Q_h
    \end{equation}
    which, again, is a Galerkin orthogonality property.
\end{remark}

As it has been discussed in previous sections, solutions to Problems \eqref{eqn:bnb-hilb}, \eqref{eqn:petrov-galerkin-hilb} exist and are unique if and only if BNB and BNB$_h$ conditions hold. In particular, since we are working with Hilbert spaces, BNB$_h$ conditions can be reformulated as:
\begin{align}\label{eqn:discrete infsup}\marginpar{Discrete inf-sup}
    \inf_{u_h\in V_h}\sup_{q_h\in Q_h}\frac{\langle Au_h,q_h \rangle}{\norm{u_h}_V\norm{q_h}_{Q_h}}&\geq\alpha_h>0 \\
    \inf_{q_h\in Q_h}\sup_{u_h\in V_h}\frac{\langle Au_h,q_h \rangle}{\norm{u_h}_V\norm{q_h}_{Q_h}}&\geq\alpha_h>0.
\end{align}

\begin{lemma}[CeÃ 's lemma for Petrov-Galerkin]\label{lemma:cea-petrov-galerkin}
    Assume that BNB conditions hold for both Problem \eqref{eqn:bnb-hilb} and \eqref{eqn:petrov-galerkin-hilb}. Let $u\in V$ be the solution to \eqref{eqn:bnb-hilb} and let $u_h\in V_h$ be the solution to \eqref{eqn:petrov-galerkin-hilb}. Then
    \begin{equation*}
        \norm{u-u_h}_V\leq\left( 1+\frac{\norm{A}}{\alpha_h} \right)\inf_{v_h\in V_h}\norm{u-v_h}_V.
    \end{equation*}
\end{lemma}
\rev{Should the proof follow the teacher's notes a little more? However this seems quite ok.}
\begin{proof}
    From the discrete inf-sup, we have
    \begin{equation*}
        \alpha_h\leq \inf_{v_h\in V_h}\sup_{q_h\in Q_h}\frac{\langle Av_h,q_h \rangle}{\norm{v_h}_V\norm{q_h}_{Q_h}}= \inf_{v_h\in V_h}\frac{\norm{Av_h}_{*,Q_h}}{\norm{v_h}_V},
    \end{equation*}
    where $\norm{\cdot}_{*,Q_h}$ is the operator norm on the space $Q_h$ (i.e. the last equality follows by the definition of $\norm{\cdot}_{*,Q_h}$). From this follows that
    \begin{equation*}
        \frac{1}{\alpha_h}\norm{Av_h}_{*,Q_h}\geq\norm{v_h}_V \quad \forall\, v_h\in V_h.
    \end{equation*}
    In particular, it is also true that
    \begin{equation*}
        \frac{1}{\alpha_h}\norm{A(u_h-v_h)}_{*,Q_h}\geq\norm{u_h-v_h}_V \quad \forall\, v_h\in V_h,
    \end{equation*}
    since clearly $u_h-v_h\in V_h$. Now, we start doing some inequalities:
    \begin{align*}
        \norm{u-u_h}_V&\leq\norm{u-v_h}_V+\norm{v_h-u_h}_V\\
        &\leq\norm{u-v_h}_V+\frac{1}{\alpha_h}\norm{A(v_h-u_h)}_{*,Q_h}
    \end{align*}
    for all $v_h\in V_h$. At this point, to conclude it is enough to observe that
    \begin{align*}
        \norm{A(v_h-u_h)}_{*,Q_h}&=\sup_{q_h\in Q_h}\frac{\langle A(v_h-u_h),q_h \rangle}{\norm{q_h}_{Q_h}}\\
        &=\sup_{q_h\in Q_h}\frac{\langle A(v_h-u),q_h \rangle + \langle A(u-u_h),q_h\rangle}{\norm{q_h}_{Q_h}}\\
        &=\sup_{q_h\in Q_h}\frac{\langle A(v_h-u),q_h \rangle}{\norm{q_h}_{Q_h}}\\
        &=\norm{A(v_h-u)}_{*,Q_h},
    \end{align*}
    where we used \eqref{eqn:petrov-galerkin orthogonality} for the third equality. Plugging this into the inequality we obtained previously yields
    \begin{align*}
        \norm{u-u_h}_V&\leq\norm{u-v_h}_V+\frac{1}{\alpha_h}\norm{A(v_h-u)}_{*,Q_h}\\
        &\leq\left( 1+\frac{\norm{A}}{\alpha_h} \right)\norm{v_h-u}_V,
    \end{align*}
    for all $v_h\in V_h$. Taking the inf on $V_h$ gives the wanted inequality.
\end{proof}

It has been proved by J. Xu and L. Zikatanov in~\cite{xu03} that the bound in Lemma \ref{lemma:cea-petrov-galerkin} can be slightly sharpened by removing "$1$" from the multiplicative constant. However, the result is mainly aesthetic, since it does not yield a significant benefit in many applications.


\section{Mixed Problems}
Saddle point problems are a class of optimization problems characterized by the presence of both primal and dual variables, leading to solutions that are critical points of a Lagrangian function. These problems are common in various applications such as fluid dynamics, structural mechanics and optimization.\par
The setting is the following: take two Hilbert spaces $V,Q$ and two linear continuous operators
\begin{equation*}
    A:V\to V', \quad B:V\to Q'.
\end{equation*}
Take also $f\in V'$ and $g\in Q'$. The problem we aim to solve is: find $(u, p)\in V\times Q$ such that
\begin{equation}\label{eqn:general mixed prb} \marginpar{General mixed problem}
    \begin{cases}
        Au + B^Tp = f \quad &\text{in} \ V' \\
        Bu = g  \quad &\text{in} \ Q'.
    \end{cases}
\end{equation}

\begin{remark}
    Assume that $g$ is in the image of $B$. Then there exists $u_g\in V$ such that $Bu_g=g$. Call $Z:=\ker{B}$; then the solution $u\in V$ can be written as $u=u_0 + u_g$ for some $u_0\in Z$. Substituting in \eqref{eqn:general mixed prb} we obtain:
    \begin{equation}\label{eqn:u0 prb}
        \begin{cases}
            Au_0 + B^Tp = f - Au_g=:\Tilde{f} \\
            Bu_0 = 0
        \end{cases}
    \end{equation}
    and the second equation is satisfied automatically by construction.
\end{remark}

By the previous Remark, we can therefore restrict ourselves to the study of the so-called ``$u_0$ problem'', i.e. finding $u_0\in Z$ such that
\begin{equation*}
    \langle Au_0,v_0 \rangle + \langle B^Tp,v_0 \rangle = \langle \Tilde{f},v_0 \rangle \quad \forall \ v_0\in Z.
\end{equation*}
This is just the first equation in \eqref{eqn:u0 prb}, written in terms of duality and restricted to $Z = \ker B$. Since $v_0\in Z$, the second term of the left-hand side vanishes, and thus we are left with the equation
\begin{equation*}
    \langle Au_0,v_0 \rangle = \langle \Tilde{f},v_0 \rangle \quad \forall \ v_0\in Z.
\end{equation*}
As we have said multiple times, the solution $u_0\in Z$ to this problem exists and is unique if and only if BNB conditions hold in $Z$. Explicitly, we ask that there exists an $\alpha>0$ such that
\begin{align}\label{eqn:ell-ker conditions}\marginpar{Ell-ker conditions}
    \inf_{v_0\in Z}\sup_{u_0\in Z}\frac{\langle Au_0,v_0 \rangle}{\norm{u_0}_V\norm{v_0}_V}&\geq\alpha \\
    \inf_{u_0\in Z}\sup_{v_0\in Z}\frac{\langle Au_0,v_0 \rangle}{\norm{u_0}_V\norm{v_0}_V}&\geq\alpha.
\end{align}
In this setting, BNB conditions are also called \emph{ell-ker conditions} (for ellipticity in the kernel).\par
If we manage to solve the $u_0$-problem, the solution to the original problem can be found by solving the \emph{$p$-problem}: find $p\in Q$ such that
\begin{align*}
    \langle B^Tp,v\rangle &= -\langle Au,v\rangle + \langle f,v\rangle\\
    &= -\langle Au_0,v\rangle + \langle\Tilde{f},v\rangle \quad \forall v\in V.
\end{align*}
Let $L = \tilde{f} - Au_0$ and notice that $L \in Z^\perp = \ker B^\perp$. If we require $B$ to be surjective, by the closed range theorem \ref{thm:closed_range} we obtain $\ker B^\perp = \im(B^T)$, therefore a solution $p$ exists; it is also unique, because $B$ surjective implies $B^T$ injective.

Surjectivity of $B$ is equivalent to the inf-sup condition on $B^T$:
\begin{equation}\label{eqn:infsup-on-BT}\marginpar{inf-sup condition on $B^T$}
    \inf_{p\in Q}\sup_{v\in V}\frac{\langle Bv,p \rangle}{\norm{v}_V\norm{p}_Q}\geq\beta>0
\end{equation}
In conclusion, if conditions \eqref{eqn:ell-ker conditions} and \eqref{eqn:infsup-on-BT} hold, then there is a unique solution $(u,p)\in V\times Q$ for the mixed problem \eqref{eqn:general mixed prb}.\par
Now we want to investigate whether we can estimate the norm of the solution in terms of $f,g$ and the inf-sup constants $\alpha$ and $\beta$. First observe that, from \eqref{eqn:ell-ker conditions} and the definition of $\Tilde{f}$, it follows immediately that
\begin{equation*}
    \norm{u_0}_V\leq\frac{1}{\alpha}\norm{\Tilde{f}}_{V'}\leq\frac{1}{\alpha}\left( 
\norm{f}_{V'}+\norm{A}_*\norm{u_g}_V \right).
\end{equation*}
Moreover, being $B$ surjective, we can apply Lemma \ref{lemma:const-uniqueness} to get
\begin{equation*}
    \norm{g}_{Q'}=\norm{Bu_g}_{Q'}\geq\beta\norm{u_g}_V.
\end{equation*}
Hence 
\begin{align*}
    \norm{u}_V &= \norm{u_0+u_g}_V\\
    &\leq\frac{1}{\alpha}\left(\norm{f}_{V'}+\norm{A}_*\norm{u_g}_V \right)+\frac{1}{\beta}\norm{g}_{Q'}\\
    &\leq \frac{1}{\alpha}\norm{f}_{V'}+\left( \frac{\alpha+\norm{A}_*}{\alpha\beta}\right)\norm{g}_{Q'}.
\end{align*}
An analogous computation can be made for $p,$ showing that
\begin{equation*}
    \norm{p}_Q\leq\frac{\norm{A}_*+\alpha}{\alpha\beta}\norm{f}_{V'}+\frac{\norm{A}_*}{\beta}\left(\frac{\norm{A}_*+\alpha}{\alpha\beta}\right)\norm{g}_{Q'}.
\end{equation*}
\begin{remark}
    Call $\mathbb{V}:=V\times Q$ and
    \begin{equation*}
        \mathbb{A}:=\begin{bmatrix}
            A & B^T\\
            B & 0
        \end{bmatrix}\in\L(\mathbb{V};\mathbb{V}').
    \end{equation*}
    Problem \eqref{eqn:general mixed prb} can clearly be stated in terms of a singular variable $\psi:=(u,p)\in\mathbb{V}$ and the linear operator $\mathbb{A}$. It can be proved (but it is not easy) that conditions \eqref{eqn:ell-ker conditions}, \eqref{eqn:infsup-on-BT} are equivalent to the existence of a constant $\overline{\alpha}>0$ such that
    \begin{align}
        \inf_{\psi\in \mathbb{V}}\sup_{\theta\in \mathbb{V}}\frac{\langle A\psi,\theta \rangle}{\norm{\psi}_\mathbb{V}\norm{\theta}_\mathbb{V}}&\geq\overline{\alpha} \\
        \inf_{\theta\in \mathbb{V}}\sup_{\psi\in \mathbb{V}}\frac{\langle A\psi,\theta \rangle}{\norm{\psi}_\mathbb{V}\norm{\theta}_\mathbb{V}}&\geq\overline{\alpha}.
    \end{align}
    This is known in the literature as \emph{``Brezzi $\iff$ Babu\v{s}ka''}.
\end{remark}

\subsection{A priori error estimates for mixed problems}
This paragraph aims to give an idea of why mixed problems are challenging to tackle numerically. Take for simplicity a conformal approximation setting $V_h \subset V$, $Q_h \subset Q$ and consider the discrete counterpart of Problem \eqref{eqn:general mixed prb}: find $u_h \in V_h$ and $p_h \in Q_h$ s.t.
\begin{equation}\label{eqn:discrete-mixed-prb} \marginpar{Discrete mixed problem}
	\begin{cases}
		Au_h + B^Tp_h = f \quad &\text{in} \ {V_h}' \\
		Bu_h = g  \quad &\text{in} \ {Q_h}'.
	\end{cases}
\end{equation}
In analogy with the continuous case, well-posedness depends on satisfying:
\begin{itemize}
	\item ell-ker conditions for $A_h: V_h \to {V_h}'$ (either is sufficient, since the setting has become finite dimensional),
	\item the inf-sup condition on $B_h^T$, where $B_h: V_h \to {Q_h}'$.
\end{itemize}
In particular, the constants $\alpha_h$ and $\beta_h$ provided by these conditions must be \emph{uniformly} bounded from below by some positive numbers, otherwise the solution's approximation would fail.

The subspace in which discrete ell-ker conditions are to be satisfied is
\begin{equation*}
	Z_h:=\{ v_h\in V_h \mid \langle Bv_h,q_h\rangle=0 \ \forall\,q_h\in Q_h \}
\end{equation*}
which is the discrete analogue of $Z = \ker B$. What this space contains depends, \emph{at the same time}, on the choice of both the approximation spaces $V_h$ and $Q_h$. Moreover, there is no guarantee that $Z_h \subset Z$, nor that $Z_h \supset Z$: in some examples, it can even happen that $Z_h \cap Z = \{ 0 \}$. Hence, we cannot deduce discrete ell-ker conditions from those of the continuous problem automatically.
\begin{example}
    Consider $B=\dvg: (H^1)^d \to (L^2)' = L^2$. In dimension $d=1$, $B$ is just the derivative operator
    \[
    \langle Bu, q \rangle = \int u' q.
    \]
    In this case, $Z$ is the set of (a.e.) constant functions. However, if we take $Q_h = \P_D^0$, i.e. the set of piece-wise constant functions, then
    \begin{equation*}
        \langle Bv_h,q_h\rangle=0 \ \forall\, q_h\in Q_h \ \iff \ \int_T v_h'=0 \quad \forall \, T \ \text{element in the triangulation}.
    \end{equation*}
    Since elements in 1D are just intervals, applying the fundamental theorem of calculus yields that any function $v_h \in Z_h$ will have (same) constant value at each vertex of the triangulation. Hence:
    \begin{itemize}
    	\item If $V_h = \P_C^1$, i.e. $v_h$ is linear continuous, then the only possibility for $v_h$ is to be globally constant.
    	\item If $V_h = \P_C^2$, then $Z_h$ contains also all functions which are quadratic in each interval, with same value at each vertex.
    	\rev{Add a figure to show this.}
    \end{itemize}
	In the former case, $Z_h = Z$, in the latter $Z_h \supset Z$.
	
	When $d=2$, $Z$ is the space of divergence-free functions in $(H^1)^2$. Let us choose $V_h = (\P_C^1)^2$ and $Q_h = \P_D^0$. Then, in analogy with the one-dimensional case,
	\[
	Z_h = \Set{ v_h \in (\P_C^1)^2 : \int_T \dvg v_h = 0 \quad \forall T}.
	\]
	Since $v_h \in (\P_C^1)^2$, its divergence is just a constant, therefore the integral equality implies $\dvg v_h = 0$ a.e. in each element $T$, hence $\dvg v_h = 0$ a.e. globally. This proves that $Z_h \subset Z$. If we add a zero boundary condition, it is not difficult to see that $Z_h = \{0\}$, while $Z$ may be not trivial.
\end{example}

The main consequence -- and issue -- of working with $Z_h$ is that the accuracy of the approximate solution $u_h$ will depend not only on $V_h$, but also on $Q_h$. The same will happen for $p_h$ as well.
	\rev{The result below is slightly different from the one in the notes and follows Lemma 2.44 of Guermond's book. In particular, the triangle inequality argument for $\norm{u-u_h}$ in the notes doesn't work. The reason is: even taking $v_h \in Z_h$, there is no guarantee that $u_h - v_h$ is in $Z_h$.}
\begin{theorem}
	Suppose that both the continuous and discrete problem are well-posed and let $(u,p)$ be the solution to \eqref{eqn:general mixed prb}. Then the approximate solution $(u_h,p_h)$ satisfies the following inequalities:
	\begin{align}
		\norm{u-u_h}_V &\le c_{1h} \inf_{v_h\in V_h}\norm{u-v_h}_V + c_{2h} \inf_{q_h\in Q_h}\norm{p-q_h}_Q \\
		\norm{p-p_h}_Q &\le c_{3h} \inf_{v_h\in V_h}\norm{u-v_h}_V + c_{4h} \inf_{q_h\in Q_h}\norm{p-q_h}_Q.
	\end{align}
	In particular:
	\begin{itemize}
		\item $c_{1h} = \left( 1+\frac{\norm{A}_*}{\alpha_h}\right) \left( 1+\frac{\norm{B}_*}{\beta_h}\right)$,
		\item $c_{2h} = \frac{\norm{B}_*}{\alpha_h}$ \, if $Z_h \not\subset Z$, \quad $c_{2h} = 0$ \, if $Z_h \subset Z$,
		\item $c_{3h} = c_{1h} \frac{\norm{A}_*}{\beta_h}$, \quad $c_{4h} = 1 + \frac{\norm{B}_*}{\beta_h} + c_{2h} \frac{\norm{A}_*}{\beta_h}$.
	\end{itemize}
\end{theorem}
\begin{proof}
	The solution and its approximation satisfy the following equalities:
	\begin{align*}
	    \langle Au,v_h\rangle+\langle Bv_h,p\rangle&=\langle f,v_h\rangle \quad \forall\,v_h\in V_h\\
	    \langle Au_h,v_h\rangle+\langle Bv_h,p_h\rangle&=\langle f,v_h\rangle \quad \forall\,v_h\in V_h.
	\end{align*}
	Subtracting the two gives
	\begin{equation}\label{eqn:mixed-remainder}
	    \langle A(u-u_h),v_h\rangle=-\langle Bv_h,p-p_h\rangle \quad \forall\, v_h\in V_h.
	\end{equation}
	Now observe that, if we restrict ourselves to $v_h\in Z_h\subset V_h$, then $\langle Bv_h,p-p_h\rangle=\langle Bv_h,p-q_h\rangle$ for all $q_h\in Q_h$, so the previous equation can be rephrased as
	\begin{equation}\label{eqn:mixed prb orthogonality}
	    \langle A(u-u_h),v_h\rangle=-\langle Bv_h,p-q_h\rangle \quad \forall\, v_h\in Z_h \ \text{and} \ \forall\,q_h\in Q_h.
	\end{equation}
	
	Let $v_h \in V_h$. In order to derive a bound on $\norm{u-u_h}_V$, the usual argument with the triangle inequality
	\[
	\norm{u-u_h}_V\leq\norm{u-v_h}_V+\norm{v_h-u_h}_V
	\]
	needs some adjustment. In fact, since neither $v_h$ nor $u_h$ is guaranteed to be in $Z_h$, we would not be allowed to take advantage of the discrete ell-ker condition for the second term. A workaround is considering some $r_h \in V_h$ such that
	\[
	\langle Br_h , q_h \rangle = \langle B (u-v_h) , q_h \rangle \quad \forall q_h \in Q_h.
	\]
	Such $r_h$ exists for any given $v_h\in Z_h$, because $B_h$ is surjective. If we set $w_h = r_h + v_h$, we obtain that $w_h - u_h \in Z_h$. Then, the following holds:
	\begin{align*}
	    \norm{u-u_h}_V&\leq\norm{u-w_h}_V+\norm{w_h-u_h}_V\\
	    &\leq\norm{u-w_h}_V +\frac{1}{\alpha_h}\norm{A(w_h-u_h)}_{*,Z_h}
	\end{align*}
	Now, we use \eqref{eqn:mixed prb orthogonality} in the following chain of (in)equalities:
	\begin{align*}
	    \norm{A(w_h-u_h)}_{*,Z_h} &= \sup_{z_h\in Z_h}\frac{\langle A(w_h-u_h),z_h\rangle}{\norm{z_h}_{V_h}}\\
	    &= \sup_{z_h\in Z_h}\frac{\langle A(w_h-u),z_h\rangle + \langle A(u-u_h),z_h\rangle}{\norm{z_h}_{V_h}}\\
	    &= \sup_{z_h\in Z_h}\frac{\langle A(w_h-u),z_h\rangle - \langle Bz_h,p-q_h\rangle}{\norm{z_h}_{V_h}}\\
	    &\leq \norm{A}_*\norm{w_h-u}_V+\norm{B}_*\norm{p-q_h}_Q
	\end{align*}
	Notice in particular that the second contribution vanishes if $Z_h \subset Z$. Finally, $\norm{w_h-u}_V$ can be bounded as follows:
	\begin{align}
		\norm{w_h-u}_V &\le \norm{w_h-v_h}_V + \norm{v_h-u}_V \\
		&= \norm{r_h}_V + \norm{v_h-u}_V \\
		&\le \frac{\norm{B}_*}{\beta_h} \norm{u-v_h}_V + \norm{u-v_h}_V.
	\end{align}
	The last line is a consequence of Lemma \ref{lemma:const-uniqueness}, applied to $B_h$. Putting every piece together and taking the infimum over all $v_h \in V_h$ and $q_h \in Q_h$ yields the inequality for $\norm{u-u_h}_V$.
	
	To get the bound for $\norm{p-p_h}_Q$, it suffices to take any $q_h \in Q_h$ and use the triangle inequality
	\[
	\norm{p-p_h}_Q \le \norm{p-q_h}_Q + \norm{q_h-p_h}_Q.
	\]
	The second term can be bounded using the inf-sup condition for $B_h^T$ and then \eqref{eqn:mixed-remainder}:
	\begin{align}
	\norm{q_h-p_h}_Q &\le \frac{1}{\beta_h} \norm{B^T(q_h - p_h)}_{*,V_h} \\
	&\le \frac{1}{\beta_h} \left( \norm{B^T(q_h - p)}_{*,V_h} + \norm{B^T(p - p_h)}_{*,V_h} \right) \\
	&= \frac{1}{\beta_h} \sup_{v_h \in V_h} \frac{\langle  B v_h, q_h - p \rangle + \langle B v_h, p - p_h \rangle}{\norm{v_h}_{V_h}} \\
	&= \frac{1}{\beta_h} \sup_{v_h \in V_h} \frac{\langle  B v_h, q_h - p \rangle - \langle A (u-u_h) , v_h \rangle}{\norm{v_h}_{V_h}} \\
	&\le \frac{1}{\beta_h} (\norm{B}_* \norm{p-q_h}_Q + \norm{A}_*\norm{u-u_h}_V).
	\end{align}
	The result follows without difficulty.
\end{proof}


\subsection{An example: the mixed Laplacian}
Another example is the mixed formulation of the Laplacian:
\begin{equation}
    \begin{aligned}
        a(u, v) + b(v, p) &= f(v) \quad \forall v \in V, \\
        b(u, q) &= g(q) \quad \forall q \in Q.
    \end{aligned}
\end{equation}

\rev{complete this}